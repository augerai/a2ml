---
# Name of the DataSet on Auger Cloud
dataset:
# Experiment settings that are unique to Auger
experiment:
  # Latest experiment name
  name:
  # Latest experiment session
  experiment_session_id:
  # Time series feature. If Data Source contains more then one DATETIME feature
  # you will have to explicitly specify feature to use as time series
  time_series:
  # List of columns which should be used as label encoded features
  label_encoded: []
  ### Metric used to build Model
  # Score used to optimize ML model.
  # Supported scores for classification: accuracy, f1_macro, f1_micro, f1_weighted, neg_log_loss, precision_macro, precision_micro, precision_weighted, recall_macro, recall_micro, recall_weighted
  # Supported scores for binary classification: accuracy, average_precision, f1, f1_macro, f1_micro, f1_weighted, neg_log_loss, precision, precision_macro, precision_micro, precision_weighted, recall, recall_macro, recall_micro, recall_weighted, roc_auc, cohen_kappa_score, matthews_corrcoef
  # Supported scores for regression and time series: explained_variance, neg_median_absolute_error, neg_mean_absolute_error, neg_mean_squared_error, neg_mean_squared_log_error, r2, neg_rmsle, neg_mase, mda, neg_rmse
  metric: accuracy

  # Optional. Default: None. Use it if you have a lot of failed trials
  # Set it to value < 8 to give trial fit process more memory.  
  # trials_per_worker: 2

  # Optional. Default: None. Used in case of unbalanced datasets.
  # Class Weight Weights associated with classes. If None, all classes are supposed to have weight one. 
  # The Balanced mode automatically adjusts weights inversely proportional to class frequencies in the input data. 
  # The Balanced Subsample mode is the same as Balanced except that weights are computed based on the bootstrap sample for every tree grown.
  # class_weight: balanced

  # Oversampling Methods to adjust the class distribution of a data set 
  # (in binary classification if 1-class is 99% and 0-class is 1% then samples from 0-class should be added to dataset in order to prevent overfitting on majority class)
  # Name should be from imbalanced-learn library. For example: SMOTE, RandomOverSampler, ADASYN, SMOTEENN, SMOTETomek
  # Read https://imbalanced-learn.readthedocs.io/en/stable/api.html#module-imblearn.over_sampling
  # For full parameters description  
  # oversampling:
    # name: SMOTE
    # params:
    #   sampling_strategy: minority
    #   k_neighbors: 5

# CPU cluster hardware settings
cluster:
  # Type could be standard or high_memory
  type: standard
  min_nodes: 2
  max_nodes: 2
  stack_version: stable
